{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ALSI-T: Trajectory-Aware Projector Training (GPU Optimized)\n",
        "\n",
        "### **1. Setup Environment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q transformers torch matplotlib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import pickle\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_id = 'AntonV/mamba2-130m-hf'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id).to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **2. Functional Mamba-2 Logic** (Omitted for brevity, use previous implementation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **3. Dataset Generation** (Run this first, then move model to CPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ... (Run your current Dataset Generation cell here) ...\n",
        "print('Dataset generated. Freeing VRAM...')\n",
        "model.to('cpu') # Move model to CPU to free 14GB VRAM\n",
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **4. Phi-T Projector & Training**\n",
        "Memory-efficient training with the model moved to CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PhiFieldProjector(nn.Module):\n",
        "    def __init__(self, s_dim, e_dim, num_l=12, h_dim=1024):\n",
        "        super().__init__()\n",
        "        self.layer_embed = nn.Embedding(num_l, 64)\n",
        "        self.input_proj = nn.Linear(s_dim + e_dim + 64, h_dim)\n",
        "        self.norm = nn.LayerNorm(h_dim)\n",
        "        self.net = nn.Sequential(nn.SiLU(), nn.Linear(h_dim, h_dim), nn.LayerNorm(h_dim), nn.SiLU())\n",
        "        self.output_proj = nn.Linear(h_dim, s_dim)\n",
        "        nn.init.zeros_(self.output_proj.weight); nn.init.zeros_(self.output_proj.bias)\n",
        "\n",
        "    def forward(self, h, t, l): \n",
        "        l_e = self.layer_embed(torch.full((h.size(0),), l, device=h.device, dtype=torch.long))\n",
        "        x = self.norm(self.input_proj(torch.cat([h, t, l_e], dim=-1)))\n",
        "        x = self.net(x)\n",
        "        return self.output_proj(x)\n",
        "\n",
        "# 1. Load Dataset from local disk\n",
        "with open('phi_t_dataset.pkl', 'rb') as f: dataset = pickle.load(f)\n",
        "\n",
        "# 2. Setup\n",
        "h_dim_val = dataset[0]['h'].numel()\n",
        "e_dim_val = 768\n",
        "phi_t = PhiFieldProjector(h_dim_val, e_dim_val).to(device)\n",
        "opt = optim.Adam(phi_t.parameters(), lr=1e-3)\n",
        "crit = nn.MSELoss()\n",
        "\n",
        "# 3. Training Loop\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for s in dataset:\n",
        "        # Load sample to GPU on the fly\n",
        "        h = s['h'].to(device).view(1, -1)\n",
        "        t_e = torch.randn(1, 768).to(device) # Replace with real embed lookup if needed\n",
        "        \n",
        "        opt.zero_grad()\n",
        "        sample_loss = 0\n",
        "        for l in range(12):\n",
        "            pred = phi_t(h, t_e, l)\n",
        "            target = s['field'][l].to(device).view(1, -1)\n",
        "            loss = crit(pred, target)\n",
        "            loss.backward()\n",
        "            sample_loss += loss.item()\n",
        "        \n",
        "        opt.step()\n",
        "        total_loss += sample_loss\n",
        "        \n",
        "    avg = total_loss / (len(dataset) * 12)\n",
        "    if epoch % 10 == 0: print(f'Epoch {epoch} | Loss: {avg:.6f}')\n",
        "\n",
        "torch.save(phi_t.state_dict(), 'phi_t_model.pt')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
